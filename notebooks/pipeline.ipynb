{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from pyspark.sql import SparkSession\n",
    "from src.data_pipeline.ingestion import load_airbnb_data, load_geojson_data, load_rentals_data\n",
    "from src.data_pipeline.cleaning import clean_airbnb_data\n",
    "from src.data_pipeline.geo_enrichment import enrich_airbnb_data\n",
    "from src.data_pipeline.transformations import (\n",
    "    impute_review_scores, \n",
    "    transform_room_type, \n",
    "    calculate_investment_potential\n",
    ")\n",
    "from src.data_pipeline.utils import save_to_delta\n",
    "from src.data_pipeline.visualization import generate_visualizations\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Databricks Pipeline\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.1.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define file paths (adjust paths if files are in DBFS)\n",
    "airbnb_path = \"/dbfs/FileStore/tables/airbnb.csv\"\n",
    "geojson_path = \"/dbfs/FileStore/tables/post_codes.geojson\"\n",
    "rentals_path = \"/dbfs/FileStore/tables/rentals.json\"\n",
    "output_path = \"/dbfs/delta\"\n",
    "\n",
    "# Step 1: Load Airbnb and GeoJSON data\n",
    "airbnb_df = load_airbnb_data(spark, airbnb_path)\n",
    "geojson_df = load_geojson_data(spark, geojson_path)\n",
    "\n",
    "# Step 2: Clean and enrich Airbnb data\n",
    "airbnb_cleaned = clean_airbnb_data(airbnb_df)\n",
    "airbnb_enriched = enrich_airbnb_data(airbnb_cleaned, geojson_df)\n",
    "\n",
    "# Step 3: Apply transformations\n",
    "airbnb_transformed = impute_review_scores(airbnb_enriched)\n",
    "airbnb_transformed = transform_room_type(airbnb_transformed)\n",
    "\n",
    "# Step 4: Load rental data\n",
    "rentals_df = load_rentals_data(spark, rentals_path)\n",
    "\n",
    "# Step 5: Calculate investment potential\n",
    "investment_metrics = calculate_investment_potential(airbnb_transformed, rentals_df)\n",
    "\n",
    "# Step 6: Save outputs to Delta tables\n",
    "save_to_delta(airbnb_transformed, f\"{output_path}/airbnb_gold\")\n",
    "save_to_delta(investment_metrics, f\"{output_path}/investment_metrics\")\n",
    "\n",
    "# Step 7: Generate visualizations\n",
    "generate_visualizations(airbnb_transformed, f\"{output_path}/visualizations\")\n",
    "\n",
    "# End Spark Session\n",
    "spark.stop()\n",
    "\n",
    "print(\"Pipeline executed successfully. Outputs saved to Delta tables.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
